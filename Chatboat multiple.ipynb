{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:03.805324Z",
     "start_time": "2025-09-03T14:35:02.097530Z"
    }
   },
   "source": [
    "## tools\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:03.938308Z",
     "start_time": "2025-09-03T14:35:03.820929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"Query arxiv papers\")\n",
    "print(arxiv.name)"
   ],
   "id": "6d12ffe971ea3b55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:06.671495Z",
     "start_time": "2025-09-03T14:35:03.955295Z"
    }
   },
   "cell_type": "code",
   "source": "arxiv.invoke(\"Attention is all you need\")",
   "id": "b971ffd967e604f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time o\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:06.861503Z",
     "start_time": "2025-09-03T14:35:06.696194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n"
   ],
   "id": "4c00c74d808b5f21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:15.453953Z",
     "start_time": "2025-09-03T14:35:06.876623Z"
    }
   },
   "cell_type": "code",
   "source": "wiki.invoke(\"shahrukh khan\")",
   "id": "363068578acc2fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Shah Rukh Khan\\nSummary: Shahrukh Khan (pronounced [ˈʃaːɦɾʊx xäːn] ; born 2 November 1965), and popularly known by the initials SRK, is an Indian actor and film producer renowned for his work in Hindi cinema. Referred to in the media as the \"Baadshah of Bollywood\" and \"King Khan\", he has appeared in more than 100 films, and earned numerous accolades, including a National Film Award and 15 Filmfare Awards. He has been awarded the Padma Shri by the Government of India, as well as the Order of'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:15.480826Z",
     "start_time": "2025-09-03T14:35:15.474688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"TAVILY_API_KEY\"]=\"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\""
   ],
   "id": "653a810c88a1dee4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:52.583458Z",
     "start_time": "2025-09-03T14:35:52.577265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults()"
   ],
   "id": "431fe68de2e136aa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:23.128877Z",
     "start_time": "2025-09-03T14:35:15.779360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tavily.invoke(\"provide me the recent ai news\"\n",
    "              )"
   ],
   "id": "a3e69732619f0409",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tavily\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprovide me the recent ai news\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m               )\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\tools\\base.py:604\u001B[0m, in \u001B[0;36mBaseTool.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    598\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    601\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    602\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    603\u001B[0m     tool_input, kwargs \u001B[38;5;241m=\u001B[39m _prep_run_args(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 604\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun(tool_input, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\tools\\base.py:888\u001B[0m, in \u001B[0;36mBaseTool.run\u001B[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_to_raise:\n\u001B[0;32m    887\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_tool_error(error_to_raise)\n\u001B[1;32m--> 888\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error_to_raise\n\u001B[0;32m    889\u001B[0m output \u001B[38;5;241m=\u001B[39m _format_output(content, artifact, tool_call_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, status)\n\u001B[0;32m    890\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_tool_end(output, color\u001B[38;5;241m=\u001B[39mcolor, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\tools\\base.py:857\u001B[0m, in \u001B[0;36mBaseTool.run\u001B[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[0m\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config_param \u001B[38;5;241m:=\u001B[39m _get_runnable_config_param(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run):\n\u001B[0;32m    856\u001B[0m         tool_kwargs \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m {config_param: config}\n\u001B[1;32m--> 857\u001B[0m     response \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run, \u001B[38;5;241m*\u001B[39mtool_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtool_kwargs)\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent_and_artifact\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(response) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_community\\tools\\tavily_search\\tool.py:175\u001B[0m, in \u001B[0;36mTavilySearchResults._run\u001B[1;34m(self, query, run_manager)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# TODO: remove try/except, should be handled by BaseTool\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 175\u001B[0m     raw_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_wrapper\u001B[38;5;241m.\u001B[39mraw_results(\n\u001B[0;32m    176\u001B[0m         query,\n\u001B[0;32m    177\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_results,\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_depth,\n\u001B[0;32m    179\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_domains,\n\u001B[0;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexclude_domains,\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_answer,\n\u001B[0;32m    182\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_raw_content,\n\u001B[0;32m    183\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minclude_images,\n\u001B[0;32m    184\u001B[0m     )\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mrepr\u001B[39m(e), {}\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_community\\utilities\\tavily_search.py:60\u001B[0m, in \u001B[0;36mTavilySearchAPIWrapper.raw_results\u001B[1;34m(self, query, max_results, search_depth, include_domains, exclude_domains, include_answer, include_raw_content, include_images)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraw_results\u001B[39m(\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     40\u001B[0m     query: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     47\u001B[0m     include_images: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     48\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict:\n\u001B[0;32m     49\u001B[0m     params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     50\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_key\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtavily_api_key\u001B[38;5;241m.\u001B[39mget_secret_value(),\n\u001B[0;32m     51\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m: query,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_images\u001B[39m\u001B[38;5;124m\"\u001B[39m: include_images,\n\u001B[0;32m     59\u001B[0m     }\n\u001B[1;32m---> 60\u001B[0m     response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTAVILY_API_URL\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/search\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     62\u001B[0m         json\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m     63\u001B[0m     )\n\u001B[0;32m     64\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\requests\\api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[1;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\requests\\adapters.py:644\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    641\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    643\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 644\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[0;32m    645\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    646\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    647\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[0;32m    648\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    649\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    650\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    651\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    652\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    653\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[0;32m    654\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    655\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    656\u001B[0m     )\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    790\u001B[0m     conn,\n\u001B[0;32m    791\u001B[0m     method,\n\u001B[0;32m    792\u001B[0m     url,\n\u001B[0;32m    793\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    794\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    795\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    796\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    797\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    798\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    799\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    800\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    802\u001B[0m )\n\u001B[0;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\urllib3\\connection.py:507\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    510\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\http\\client.py:1428\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1427\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1428\u001B[0m         response\u001B[38;5;241m.\u001B[39mbegin()\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1430\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\http\\client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_status()\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\http\\client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mreadline(_MAXLINE \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\socket.py:720\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    719\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 720\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[0;32m    721\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    722\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\ssl.py:1251\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1247\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1248\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1249\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1250\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\ssl.py:1103\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1104\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1105\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:45.635786Z",
     "start_time": "2025-09-03T14:35:45.631087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## combine all these tools in the list\n",
    "tools = [arxiv,wiki,tavily]"
   ],
   "id": "4d88bab375bf407d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:57.358408Z",
     "start_time": "2025-09-03T14:35:55.735438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## initialize the LLm model\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model= \"qwen/qwen3-32b\")"
   ],
   "id": "35af82e0e6897d24",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:36:13.075665Z",
     "start_time": "2025-09-03T14:36:09.953212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.invoke(\"What is Ai\")\n",
    "print(response)"
   ],
   "id": "f62a3d14f156129c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user is asking what AI is. Let me start by defining it simply. AI, or Artificial Intelligence, is the simulation of human intelligence in machines. But I need to go beyond that basic definition.\\n\\nFirst, mention the core areas like machine learning and deep learning. Maybe explain how machines can learn from data instead of just following strict programming. Include examples like image recognition or language processing to make it relatable.\\n\\nAlso, touch on different types of AI—narrow AI versus general AI. Most current systems are narrow, focused on specific tasks. General AI is still theoretical. Highlight real-world applications: virtual assistants, recommendation systems, autonomous vehicles. These examples show practical uses.\\n\\nDon\\'t forget the history. Mention early concepts from the mid-20th century, like the Turing Test. Then move to modern advancements with big data and computing power. Maybe note key milestones, like IBM\\'s Deep Blue or AlphaGo.\\n\\nAddress the challenges and ethical concerns too. Issues like data privacy, bias in algorithms, job displacement. Also, mention the potential benefits: healthcare improvements, environmental solutions, etc.\\n\\nStructure the answer to be clear and concise. Start with a definition, then break down components, applications, history, and implications. Avoid jargon where possible. Make sure the user walks away understanding both what AI is and its significance in today\\'s world.\\n</think>\\n\\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and perform tasks typically requiring human cognition. These tasks include problem-solving, decision-making, language understanding, pattern recognition, and adapting to new information. AI systems are designed to improve their performance over time through experience, often by analyzing vast amounts of data.\\n\\n### Key Components of AI:\\n1. **Machine Learning (ML):**  \\n   A subset of AI where algorithms learn patterns from data without being explicitly programmed. For example, recommendation systems (like those on Netflix or Amazon) use ML to predict user preferences.\\n\\n2. **Deep Learning:**  \\n   A type of ML inspired by the structure of the human brain (neural networks). It excels in tasks like image and speech recognition (e.g., facial recognition or voice assistants like Siri/Alexa).\\n\\n3. **Natural Language Processing (NLP):**  \\n   Enables machines to understand and generate human language. Examples include chatbots (e.g., customer service bots) and translation tools (e.g., Google Translate).\\n\\n4. **Computer Vision:**  \\n   Allows machines to interpret and analyze visual data, such as identifying objects in photos or enabling self-driving cars to \"see\" their environment.\\n\\n### Types of AI:\\n- **Narrow AI (Weak AI):**  \\n  Designed for specific tasks (e.g., spam filters, chess-playing algorithms like IBM’s Deep Blue). Most current AI systems fall into this category.\\n- **General AI (Strong AI):**  \\n  Hypothetical AI that possesses human-like general intelligence, capable of reasoning, understanding, and learning across diverse domains. This remains a theoretical concept.\\n\\n### Applications of AI:\\n- **Healthcare:** Diagnosing diseases, drug discovery, and personalized treatment plans.\\n- **Finance:** Fraud detection, algorithmic trading, and risk management.\\n- **Transportation:** Autonomous vehicles and traffic optimization.\\n- **Retail:** Demand forecasting, inventory management, and personalized shopping experiences.\\n- **Manufacturing:** Predictive maintenance and quality control.\\n\\n### History of AI:\\n- **1950s–1970s:** The term \"AI\" was coined in 1956. Early experiments included the Turing Test (assessing machine intelligence) and rule-based systems.\\n- **1980s–1990s:** Expert systems and AI-driven applications in niche fields (e.g., medical diagnosis).\\n- **2000s–Present:** Explosive growth due to big data, cloud computing, and advances in neural networks. Landmark achievements include IBM’s *Watson*, AlphaGo (defeating human Go champions), and AI-powered tools like ChatGPT.\\n\\n### Ethical and Societal Impacts:\\n- **Benefits:** Enhanced efficiency, innovation, and solutions to complex problems (e.g., climate modeling, pandemic response).\\n- **Challenges:**  \\n  - **Bias and Fairness:** AI systems can inherit biases from training data.  \\n  - **Privacy Concerns:** Data collection for AI raises issues about surveillance and consent.  \\n  - **Job Displacement:** Automation may replace certain jobs, though it also creates new opportunities.  \\n  - **Security Risks:** AI can be misused for deepfakes, misinformation, or autonomous weapons.\\n\\nAI is a transformative technology reshaping industries and daily life. While it offers immense potential, its development requires careful consideration of ethical, legal, and societal implications to ensure it benefits humanity equitably.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 989, 'prompt_tokens': 11, 'total_tokens': 1000, 'completion_time': 2.5522872530000003, 'prompt_time': 0.011718956, 'queue_time': 0.100974833, 'total_time': 2.564006209}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--9d5b9922-1ab8-4810-8304-c361cbdaf14e-0' usage_metadata={'input_tokens': 11, 'output_tokens': 989, 'total_tokens': 1000}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:36:03.409942Z",
     "start_time": "2025-09-03T14:36:03.388904Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools = llm.bind_tools(tools=tools)\n",
   "id": "579c528809910de6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:35:23.171750300Z",
     "start_time": "2025-09-03T09:24:11.113569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Execute this call\n",
    "\n",
    "llm_with_tools.invoke(\"What is the recent news on ai\")"
   ],
   "id": "eab0891870434401",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for recent news on AI. I need to figure out which tool to use here. Let me check the available tools. There\\'s arxiv, wikipedia, and tavily_search_results_json. \\n\\nArxiv is for academic papers, so maybe not the best choice for recent news. Wikipedia is good for general information but might not have the latest updates. The third option is tavily_search_results_json, which is described as a search engine optimized for current events. That sounds perfect for recent news.\\n\\nSo I should use tavily_search_results_json with the query \"recent news on AI\". Let me make sure the parameters are correct. The function requires a \"query\" parameter, which I\\'ll set to \"recent news on AI\". No other parameters needed. \\n\\nI need to structure the tool call correctly. The name should be tavily_search_results_json and the arguments should be a JSON object with the query. Let me double-check the syntax. Yep, that should work. Alright, time to put it all together.\\n', 'tool_calls': [{'id': '823f6r06a', 'function': {'arguments': '{\"query\":\"recent news on AI\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 353, 'total_tokens': 594, 'completion_time': 0.93737204, 'prompt_time': 0.020918987, 'queue_time': 0.045379863, 'total_time': 0.958291027}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6c6bef37-52f0-44a2-aae8-6efa0e86e3f1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'recent news on AI'}, 'id': '823f6r06a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 353, 'output_tokens': 241, 'total_tokens': 594})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T14:36:20.287588Z",
     "start_time": "2025-09-03T14:36:18.471360Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(\"What is the latest research on quantum computing\")",
   "id": "bc91ea9c2502b2a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking about the latest research on quantum computing. I need to figure out which tool to use here. The available tools are arxiv, wikipedia, and tavily_search. \\n\\nArxiv is great for academic papers, so that\\'s probably the best place to look for the latest research. Wikipedia might give general information but not the most recent studies. Tavily search is for current events, but quantum computing research is more likely to be found in academic databases.\\n\\nSo I should use the arxiv function. The parameter required is a query. The user\\'s query is \"latest research on quantum computing\". I need to format that into the arxiv function call. The query parameter should be a string. Maybe I can use a keyword like \"quantum computing\" and add a date range to get the latest results. But the function\\'s parameters don\\'t mention date ranges. The description just says \"search query to look up\". So I\\'ll stick with the main keywords. \\n\\nI\\'ll set the query to \"quantum computing\" and use the arxiv function. The user might want recent papers, so perhaps the function will return the latest ones by default. That should cover it. Let me structure the tool call accordingly.\\n', 'tool_calls': [{'id': '9zasd1n2t', 'function': {'arguments': '{\"query\":\"quantum computing\"}', 'name': 'arxiv'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 276, 'prompt_tokens': 354, 'total_tokens': 630, 'completion_time': 0.791826282, 'prompt_time': 0.088227119, 'queue_time': 0.07151253, 'total_time': 0.880053401}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b30e0a3a-1da4-4b61-aa2e-b3a567996eb7-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'quantum computing'}, 'id': '9zasd1n2t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 354, 'output_tokens': 276, 'total_tokens': 630})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Workflow",
   "id": "ddee171a44bdab87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T15:03:47.873641Z",
     "start_time": "2025-09-03T15:03:47.861682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## State Schema\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage, HumanMessage  ## Human message or Ai message\n",
    "from typing import Annotated ## Labelling\n",
    "from langgraph.graph.message import add_messages ## REDUCERS IN lANGGRAPH\n"
   ],
   "id": "1e7e69f44c49b3b9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T15:05:49.378625Z",
     "start_time": "2025-09-03T15:05:49.365061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage],add_messages]\n"
   ],
   "id": "83c7d4d935fecdfc",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T15:11:26.358959Z",
     "start_time": "2025-09-03T15:11:26.351693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ],
   "id": "d608f09f70d9e767",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T15:14:24.217865Z",
     "start_time": "2025-09-03T15:14:24.207109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tool_calling_llm(state:State):\n",
    "    return{\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}"
   ],
   "id": "862cd3e9923fea56",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T17:48:22.055654Z",
     "start_time": "2025-09-03T17:48:20.500917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Build graph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "## Edges\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call ->tools_condition routes to End\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "graph = builder.compile()\n",
    "\n",
    "#view\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "54721aed3ee937ab",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T17:53:47.022669Z",
     "start_time": "2025-09-03T17:53:26.688909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = graph.invoke({\"messages\": \"1706.03762\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "id": "68c9208f33655726",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "1706.03762\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (whw2yzmbw)\n",
      " Call ID: whw2yzmbw\n",
      "  Args:\n",
      "    query: 1706.03762\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, base\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T17:55:23.394695Z",
     "start_time": "2025-09-03T17:55:22.222454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = graph.invoke({\"messages\": \"Hi i am ashish\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "id": "bf6af8e30c2a821a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi i am ashish\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Ashish! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T17:58:27.451030Z",
     "start_time": "2025-09-03T17:58:21.631946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Build graph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "## Edges\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call ->tools_condition routes to End\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "graph = builder.compile()\n",
    "\n",
    "#view\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "69b91be2b58a0da4",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:03:55.003228Z",
     "start_time": "2025-09-03T18:03:52.808834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = graph.invoke({\"messages\": \"what is recent ai news and please tell me about recent research on quantum computing\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "id": "cc836b3d827fd877",
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_exceptions.py:10\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[1;34m(map)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:  \u001B[38;5;66;03m# noqa: PIE786\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_backends\\sync.py:206\u001B[0m, in \u001B[0;36mSyncBackend.connect_tcp\u001B[1;34m(self, host, port, timeout, local_address, socket_options)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m--> 206\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    207\u001B[0m         address,\n\u001B[0;32m    208\u001B[0m         timeout,\n\u001B[0;32m    209\u001B[0m         source_address\u001B[38;5;241m=\u001B[39msource_address,\n\u001B[0;32m    210\u001B[0m     )\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m option \u001B[38;5;129;01min\u001B[39;00m socket_options:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\socket.py:841\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, all_errors)\u001B[0m\n\u001B[0;32m    840\u001B[0m exceptions \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 841\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m getaddrinfo(host, port, \u001B[38;5;241m0\u001B[39m, SOCK_STREAM):\n\u001B[0;32m    842\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\socket.py:976\u001B[0m, in \u001B[0;36mgetaddrinfo\u001B[1;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[0;32m    975\u001B[0m addrlist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m _socket\u001B[38;5;241m.\u001B[39mgetaddrinfo(host, port, family, \u001B[38;5;28mtype\u001B[39m, proto, flags):\n\u001B[0;32m    977\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "\u001B[1;31mgaierror\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mConnectError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_transports\\default.py:69\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[1;34m()\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 69\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    267\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_closed(status)\n\u001B[1;32m--> 268\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 251\u001B[0m     response \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mhandle_request(request)\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001B[39;00m\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;66;03m# indicates we need to retry the request on a new connection.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001B[39;00m\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# up as HTTP/1.1.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:99\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     98\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 99\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mis_available():\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:76\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 76\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect(request)\n\u001B[0;32m     78\u001B[0m     ssl_object \u001B[38;5;241m=\u001B[39m stream\u001B[38;5;241m.\u001B[39mget_extra_info(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mssl_object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001B[0m, in \u001B[0;36mHTTPConnection._connect\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconnect_tcp\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m--> 124\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_backend\u001B[38;5;241m.\u001B[39mconnect_tcp(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    125\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m stream\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_backends\\sync.py:205\u001B[0m, in \u001B[0;36mSyncBackend.connect_tcp\u001B[1;34m(self, host, port, timeout, local_address, socket_options)\u001B[0m\n\u001B[0;32m    200\u001B[0m exc_map: ExceptionMapping \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    201\u001B[0m     socket\u001B[38;5;241m.\u001B[39mtimeout: ConnectTimeout,\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;167;01mOSError\u001B[39;00m: ConnectError,\n\u001B[0;32m    203\u001B[0m }\n\u001B[1;32m--> 205\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    206\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    207\u001B[0m         address,\n\u001B[0;32m    208\u001B[0m         timeout,\n\u001B[0;32m    209\u001B[0m         source_address\u001B[38;5;241m=\u001B[39msource_address,\n\u001B[0;32m    210\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\contextlib.py:158\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgen\u001B[38;5;241m.\u001B[39mthrow(value)\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[1;34m(map)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[1;32m---> 14\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mConnectError\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mConnectError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\groq\\_base_client.py:980\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[0;32m    979\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 980\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39msend(\n\u001B[0;32m    981\u001B[0m         request,\n\u001B[0;32m    982\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_stream_response_body(request\u001B[38;5;241m=\u001B[39mrequest),\n\u001B[0;32m    983\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    984\u001B[0m     )\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_auth(\n\u001B[0;32m    915\u001B[0m     request,\n\u001B[0;32m    916\u001B[0m     auth\u001B[38;5;241m=\u001B[39mauth,\n\u001B[0;32m    917\u001B[0m     follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[0;32m    918\u001B[0m     history\u001B[38;5;241m=\u001B[39m[],\n\u001B[0;32m    919\u001B[0m )\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_redirects(\n\u001B[0;32m    943\u001B[0m         request,\n\u001B[0;32m    944\u001B[0m         follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[0;32m    945\u001B[0m         history\u001B[38;5;241m=\u001B[39mhistory,\n\u001B[0;32m    946\u001B[0m     )\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_single_request(request)\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_client.py:1015\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1015\u001B[0m     response \u001B[38;5;241m=\u001B[39m transport\u001B[38;5;241m.\u001B[39mhandle_request(request)\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_transports\\default.py:232\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    220\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    221\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    222\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    230\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    231\u001B[0m )\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m    233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\contextlib.py:158\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgen\u001B[38;5;241m.\u001B[39mthrow(value)\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\httpx\\_transports\\default.py:86\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[1;34m()\u001B[0m\n\u001B[0;32m     85\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(exc)\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m mapped_exc(message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[1;31mConnectError\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mAPIConnectionError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m messages \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39minvoke({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhat is recent ai news and please tell me about recent research on quantum computing\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m      3\u001B[0m     m\u001B[38;5;241m.\u001B[39mpretty_print()\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001B[0m\n\u001B[0;32m   3023\u001B[0m chunks: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m|\u001B[39m Any] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   3024\u001B[0m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m-> 3026\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[0;32m   3027\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m   3028\u001B[0m     config,\n\u001B[0;32m   3029\u001B[0m     context\u001B[38;5;241m=\u001B[39mcontext,\n\u001B[0;32m   3030\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdates\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   3031\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3032\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m stream_mode,\n\u001B[0;32m   3033\u001B[0m     print_mode\u001B[38;5;241m=\u001B[39mprint_mode,\n\u001B[0;32m   3034\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[0;32m   3035\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[0;32m   3036\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[0;32m   3037\u001B[0m     durability\u001B[38;5;241m=\u001B[39mdurability,\n\u001B[0;32m   3038\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3039\u001B[0m ):\n\u001B[0;32m   3040\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   3041\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(chunk) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001B[0m, in \u001B[0;36mPregel.stream\u001B[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001B[0m\n\u001B[0;32m   2645\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mmatch_cached_writes():\n\u001B[0;32m   2646\u001B[0m     loop\u001B[38;5;241m.\u001B[39moutput_writes(task\u001B[38;5;241m.\u001B[39mid, task\u001B[38;5;241m.\u001B[39mwrites, cached\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m-> 2647\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[0;32m   2648\u001B[0m     [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mwrites],\n\u001B[0;32m   2649\u001B[0m     timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[0;32m   2650\u001B[0m     get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[0;32m   2651\u001B[0m     schedule_task\u001B[38;5;241m=\u001B[39mloop\u001B[38;5;241m.\u001B[39maccept_push,\n\u001B[0;32m   2652\u001B[0m ):\n\u001B[0;32m   2653\u001B[0m     \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[0;32m   2654\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _output(\n\u001B[0;32m   2655\u001B[0m         stream_mode, print_mode, subgraphs, stream\u001B[38;5;241m.\u001B[39mget, queue\u001B[38;5;241m.\u001B[39mEmpty\n\u001B[0;32m   2656\u001B[0m     )\n\u001B[0;32m   2657\u001B[0m loop\u001B[38;5;241m.\u001B[39mafter_tick()\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001B[0m\n\u001B[0;32m    160\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 162\u001B[0m     run_with_retry(\n\u001B[0;32m    163\u001B[0m         t,\n\u001B[0;32m    164\u001B[0m         retry_policy,\n\u001B[0;32m    165\u001B[0m         configurable\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m    166\u001B[0m             CONFIG_KEY_CALL: partial(\n\u001B[0;32m    167\u001B[0m                 _call,\n\u001B[0;32m    168\u001B[0m                 weakref\u001B[38;5;241m.\u001B[39mref(t),\n\u001B[0;32m    169\u001B[0m                 retry_policy\u001B[38;5;241m=\u001B[39mretry_policy,\n\u001B[0;32m    170\u001B[0m                 futures\u001B[38;5;241m=\u001B[39mweakref\u001B[38;5;241m.\u001B[39mref(futures),\n\u001B[0;32m    171\u001B[0m                 schedule_task\u001B[38;5;241m=\u001B[39mschedule_task,\n\u001B[0;32m    172\u001B[0m                 submit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubmit,\n\u001B[0;32m    173\u001B[0m             ),\n\u001B[0;32m    174\u001B[0m         },\n\u001B[0;32m    175\u001B[0m     )\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[1;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[0;32m     40\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m task\u001B[38;5;241m.\u001B[39mproc\u001B[38;5;241m.\u001B[39minvoke(task\u001B[38;5;241m.\u001B[39minput, config)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m     44\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[1;32m--> 657\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    399\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(ret)\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 401\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[1;32mIn[23], line 2\u001B[0m, in \u001B[0;36mtool_calling_llm\u001B[1;34m(state)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtool_calling_llm\u001B[39m(state:State):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m:[llm_with_tools\u001B[38;5;241m.\u001B[39minvoke(state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m])]}\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5495\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m   5488\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m   5489\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m   5490\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5493\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[0;32m   5494\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[1;32m-> 5495\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39minvoke(\n\u001B[0;32m   5496\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m   5497\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_configs(config),\n\u001B[0;32m   5498\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[0;32m   5499\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:393\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[1;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    389\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[0;32m    390\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[0;32m    392\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatGeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m--> 393\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m    394\u001B[0m             [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[0;32m    395\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    396\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    397\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    398\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    399\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    400\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    401\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    402\u001B[0m         )\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    403\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1019\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m   1011\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m   1012\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1016\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1017\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m   1018\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m-> 1019\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_messages, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:837\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    834\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    836\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 837\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_with_cache(\n\u001B[0;32m    838\u001B[0m                 m,\n\u001B[0;32m    839\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    840\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    841\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    842\u001B[0m             )\n\u001B[0;32m    843\u001B[0m         )\n\u001B[0;32m    844\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    845\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1085\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m   1083\u001B[0m     result \u001B[38;5;241m=\u001B[39m generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1085\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m   1086\u001B[0m         messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m   1087\u001B[0m     )\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1089\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\langchain_groq\\chat_models.py:527\u001B[0m, in \u001B[0;36mChatGroq._generate\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    522\u001B[0m message_dicts, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_message_dicts(messages, stop)\n\u001B[0;32m    523\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    524\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    525\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    526\u001B[0m }\n\u001B[1;32m--> 527\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(messages\u001B[38;5;241m=\u001B[39mmessage_dicts, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response, params)\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:378\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    233\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    234\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m    235\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;124;03m    Creates a model response for the given chat conversation.\u001B[39;00m\n\u001B[0;32m    237\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[0;32m    379\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/openai/v1/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    380\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[0;32m    381\u001B[0m             {\n\u001B[0;32m    382\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[0;32m    383\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[0;32m    384\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexclude_domains\u001B[39m\u001B[38;5;124m\"\u001B[39m: exclude_domains,\n\u001B[0;32m    385\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[0;32m    386\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[0;32m    387\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[0;32m    388\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_domains\u001B[39m\u001B[38;5;124m\"\u001B[39m: include_domains,\n\u001B[0;32m    389\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_reasoning\u001B[39m\u001B[38;5;124m\"\u001B[39m: include_reasoning,\n\u001B[0;32m    390\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[0;32m    391\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[0;32m    392\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_completion_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_completion_tokens,\n\u001B[0;32m    393\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[0;32m    394\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    395\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[0;32m    396\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparallel_tool_calls\u001B[39m\u001B[38;5;124m\"\u001B[39m: parallel_tool_calls,\n\u001B[0;32m    397\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[0;32m    398\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreasoning_effort\u001B[39m\u001B[38;5;124m\"\u001B[39m: reasoning_effort,\n\u001B[0;32m    399\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreasoning_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: reasoning_format,\n\u001B[0;32m    400\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[0;32m    401\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msearch_settings\u001B[39m\u001B[38;5;124m\"\u001B[39m: search_settings,\n\u001B[0;32m    402\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[0;32m    403\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mservice_tier\u001B[39m\u001B[38;5;124m\"\u001B[39m: service_tier,\n\u001B[0;32m    404\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[0;32m    405\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstore\u001B[39m\u001B[38;5;124m\"\u001B[39m: store,\n\u001B[0;32m    406\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[0;32m    407\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[0;32m    408\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[0;32m    409\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[0;32m    410\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_logprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_logprobs,\n\u001B[0;32m    411\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[0;32m    412\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[0;32m    413\u001B[0m             },\n\u001B[0;32m    414\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[0;32m    415\u001B[0m         ),\n\u001B[0;32m    416\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[0;32m    417\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[0;32m    418\u001B[0m         ),\n\u001B[0;32m    419\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[0;32m    420\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    421\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[0;32m    422\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\groq\\_base_client.py:1242\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1229\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1230\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1237\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1238\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1239\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1240\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1241\u001B[0m     )\n\u001B[1;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\groq\\_base_client.py:1012\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1009\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRaising connection error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1012\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIConnectionError(request\u001B[38;5;241m=\u001B[39mrequest) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   1014\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[0;32m   1015\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHTTP Response: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1016\u001B[0m     request\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1020\u001B[0m     response\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m   1021\u001B[0m )\n\u001B[0;32m   1023\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mAPIConnectionError\u001B[0m: Connection error.",
      "\u001B[0mDuring task with name 'tool_calling_llm' and id 'ed55bb07-0000-ffca-1089-2033e178fc9e'"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7102065f94a12478"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
